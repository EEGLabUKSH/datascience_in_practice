
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Natural Language Processing &#8212; Data science in practice</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data science in practice</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Data Science in Practice or Neurophysiological Data
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="00-Introduction.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="01-Python.html">
   Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02-JupyterNotebooks.html">
   Jupyter Notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03-DataAnalysis.html">
   Data Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05-DataGathering.html">
   Data Gathering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06-DataWrangling.html">
   Data Wrangling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07-DataCleaning.html">
   Data Cleaning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="08-DataPrivacy%26Anonymization.html">
   Data Privacy &amp; Anonymization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="09-DataVisualization.html">
   Data Visualization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="10-Distributions.html">
   Distributions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="11-TestingDistributions.html">
   Testing Distributions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="12-StatisticalComparisons.html">
   Statistical Comparisons
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="13-OrdinaryLeastSquares.html">
   Ordinary Least Squares
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="14-LinearModels.html">
   Linear Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="15-Clustering.html">
   Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="16-DimensionalityReduction.html">
   Dimensionality Reduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="17-Classification.html">
   Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="19-EegMagic.html">
   EEG magic
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="A1-PythonPackages.html">
   Appendix: Python Packages
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="A2-Git.html">
   Appendix: Version Control
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/tutorials/18-NaturalLanguageProcessing.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Ftutorials/18-NaturalLanguageProcessing.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/tutorials/18-NaturalLanguageProcessing.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ntlk-natural-language-tool-kit">
   NTLK: Natural Language Tool Kit
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#downloading-corpora">
     Downloading Corpora
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tokenisation">
   Tokenisation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#part-of-speech-pos-tagging">
   Part-of-speech (POS) Tagging
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#named-entity-recognition-ner">
   Named Entity Recognition (NER)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stop-words">
   Stop words
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#text-encoding">
   Text Encoding
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#load-some-data">
     Load some Data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pre-processing">
     Pre-Processing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bag-of-words">
     Bag-of-Words
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#term-frequency-inverse-document-frequency-tf-idf">
     Term Frequency - Inverse Document Frequency (TF-IDF)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#applying-tf-idf">
       Applying TF-IDF
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   Conclusion
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Natural Language Processing</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ntlk-natural-language-tool-kit">
   NTLK: Natural Language Tool Kit
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#downloading-corpora">
     Downloading Corpora
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tokenisation">
   Tokenisation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#part-of-speech-pos-tagging">
   Part-of-speech (POS) Tagging
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#named-entity-recognition-ner">
   Named Entity Recognition (NER)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stop-words">
   Stop words
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#text-encoding">
   Text Encoding
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#load-some-data">
     Load some Data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pre-processing">
     Pre-Processing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bag-of-words">
     Bag-of-Words
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#term-frequency-inverse-document-frequency-tf-idf">
     Term Frequency - Inverse Document Frequency (TF-IDF)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#applying-tf-idf">
       Applying TF-IDF
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   Conclusion
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="natural-language-processing">
<h1>Natural Language Processing<a class="headerlink" href="#natural-language-processing" title="Permalink to this headline">#</a></h1>
<p>Most of the data we have encountered so far has been numerical (or at least, numerically encoded).</p>
<p>However, one of the most powerful aspects of data science is acknowledging and considering that there are vasts amounts of data available in many other modalities, with potentially valuable information, if the data can be leveraged and analyzed.</p>
<p>Here, we will introduce natural language processing (NLP), or the computational analysis of text.</p>
<div class="alert alert-success">
Natural Language Processing (NLP) is the approach of analyzing text data, with computers.
</div>
<div class="alert alert-info">
Natural Language Processing on 
<a href="https://en.wikipedia.org/wiki/Natural-language_processing" class="alert-link">wikipedia</a>.
</div><section id="ntlk-natural-language-tool-kit">
<h2>NTLK: Natural Language Tool Kit<a class="headerlink" href="#ntlk-natural-language-tool-kit" title="Permalink to this headline">#</a></h2>
<p>There are many tools for analyzing text data in Python. Here, we will use one of biggest and most prominent ones: NLTK.</p>
<p>NLTK provides interfaces to over 50 corpora and lexical resources, as well as a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning.</p>
<p>In this notebook, we will walk through some basic text-analysis using the <code class="docutils literal notranslate"><span class="pre">NLTK</span></code> package.</p>
<div class="alert alert-success">
The Natural Language Tool Kit, or NLTK, is a Python module for text-analysis. 
</div>
<div class="alert alert-info">
The NLTK organization website is 
<a href="http://www.nltk.org/" class="alert-link">here</a>
and they have a whole book of tutorials 
<a href="http://www.nltk.org/book/" class="alert-link">here</a>.
</div><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import NLTK</span>
<span class="kn">import</span> <span class="nn">nltk</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set an example sentence of &#39;data&#39; to play with</span>
<span class="n">sentence</span> <span class="o">=</span> <span class="s2">&quot;UC San Diego is a great place to study cognitive science.&quot;</span>
</pre></div>
</div>
</div>
</div>
<section id="downloading-corpora">
<h3>Downloading Corpora<a class="headerlink" href="#downloading-corpora" title="Permalink to this headline">#</a></h3>
<p>To work with text-data, you often need corpora - text datasets to compare to.</p>
<p>NLTK has many such datasets available, but doesnâ€™t install them by default (as the full set of them would be quite large). Below we will download some of these datasets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># If you hit an error downloading things in the cell below, come back to this cell, uncomment it, and run this code.</span>
<span class="c1">#   This code gives python permission to write to your disk (if it doesn&#39;t already have persmission to do so).</span>
<span class="c1"># import ssl</span>

<span class="c1"># try:</span>
<span class="c1">#     _create_unverified_https_context = ssl._create_unverified_context</span>
<span class="c1"># except AttributeError:</span>
<span class="c1">#     pass</span>
<span class="c1"># else:</span>
<span class="c1">#     ssl._create_default_https_context = _create_unverified_https_context</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download some useful data files from NLTK</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;punkt&#39;</span><span class="p">)</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;stopwords&#39;</span><span class="p">)</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;averaged_perceptron_tagger&#39;</span><span class="p">)</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;maxent_ne_chunker&#39;</span><span class="p">)</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;words&#39;</span><span class="p">)</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;treebank&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[nltk_data] Downloading package punkt to
[nltk_data]     C:\Users\User\AppData\Roaming\nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package stopwords to
[nltk_data]     C:\Users\User\AppData\Roaming\nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package averaged_perceptron_tagger to
[nltk_data]     C:\Users\User\AppData\Roaming\nltk_data...
[nltk_data]   Package averaged_perceptron_tagger is already up-to-
[nltk_data]       date!
[nltk_data] Downloading package maxent_ne_chunker to
[nltk_data]     C:\Users\User\AppData\Roaming\nltk_data...
[nltk_data]   Package maxent_ne_chunker is already up-to-date!
[nltk_data] Downloading package words to
[nltk_data]     C:\Users\User\AppData\Roaming\nltk_data...
[nltk_data]   Package words is already up-to-date!
[nltk_data] Downloading package treebank to
[nltk_data]     C:\Users\User\AppData\Roaming\nltk_data...
[nltk_data]   Package treebank is already up-to-date!
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="tokenisation">
<h2>Tokenisation<a class="headerlink" href="#tokenisation" title="Permalink to this headline">#</a></h2>
<div class="alert alert-success">
Tokenization is the process of splitting text data into 'tokens', which are meaningful pieces of data.
</div>
<div class="alert alert-info">
More information on tokenization
<a href="https://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html" class="alert-link">here</a>.
</div>
<p>Tokenization can be done at different levels - you can, for example tokenize text into sentences, and/or into words.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Tokenize our sentence, at the word level</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check out the word-tokenized data</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;UC&#39;, &#39;San&#39;, &#39;Diego&#39;, &#39;is&#39;, &#39;a&#39;, &#39;great&#39;, &#39;place&#39;, &#39;to&#39;, &#39;study&#39;, &#39;cognitive&#39;, &#39;science&#39;, &#39;.&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="part-of-speech-pos-tagging">
<h2>Part-of-speech (POS) Tagging<a class="headerlink" href="#part-of-speech-pos-tagging" title="Permalink to this headline">#</a></h2>
<div class="alert alert-success">
Part-of-Speech tagging is the process of labelling words with respect to their 'types' and relationships to other words.
</div>
<div class="alert alert-info">
Part-of-speech tagging on 
<a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging" class="alert-link">wikipedia</a>.
</div><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Apply part-of-speech tagging to our sentence</span>
<span class="n">tags</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">pos_tag</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check the POS tags for our data</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tags</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;UC&#39;, &#39;NNP&#39;), (&#39;San&#39;, &#39;NNP&#39;), (&#39;Diego&#39;, &#39;NNP&#39;), (&#39;is&#39;, &#39;VBZ&#39;), (&#39;a&#39;, &#39;DT&#39;), (&#39;great&#39;, &#39;JJ&#39;), (&#39;place&#39;, &#39;NN&#39;), (&#39;to&#39;, &#39;TO&#39;), (&#39;study&#39;, &#39;VB&#39;), (&#39;cognitive&#39;, &#39;JJ&#39;), (&#39;science&#39;, &#39;NN&#39;), (&#39;.&#39;, &#39;.&#39;)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check out the documentation for describing the abbreviations</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">help</span><span class="o">.</span><span class="n">upenn_tagset</span><span class="p">(</span><span class="n">tagpattern</span><span class="o">=</span><span class="s1">&#39;NNP&#39;</span><span class="p">)</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">help</span><span class="o">.</span><span class="n">upenn_tagset</span><span class="p">(</span><span class="n">tagpattern</span><span class="o">=</span><span class="s1">&#39;DT&#39;</span><span class="p">)</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">help</span><span class="o">.</span><span class="n">upenn_tagset</span><span class="p">(</span><span class="n">tagpattern</span><span class="o">=</span><span class="s1">&#39;JJ&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">LookupError</span><span class="g g-Whitespace">                               </span>Traceback (most recent call last)
<span class="nn">Input In [9],</span> in <span class="ni">&lt;cell line: 2&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># Check out the documentation for describing the abbreviations</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">nltk</span><span class="o">.</span><span class="n">help</span><span class="o">.</span><span class="n">upenn_tagset</span><span class="p">(</span><span class="n">tagpattern</span><span class="o">=</span><span class="s1">&#39;NNP&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">nltk</span><span class="o">.</span><span class="n">help</span><span class="o">.</span><span class="n">upenn_tagset</span><span class="p">(</span><span class="n">tagpattern</span><span class="o">=</span><span class="s1">&#39;DT&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">nltk</span><span class="o">.</span><span class="n">help</span><span class="o">.</span><span class="n">upenn_tagset</span><span class="p">(</span><span class="n">tagpattern</span><span class="o">=</span><span class="s1">&#39;JJ&#39;</span><span class="p">)</span>

<span class="nn">File ~\anaconda3\lib\site-packages\nltk\help.py:27,</span> in <span class="ni">upenn_tagset</span><span class="nt">(tagpattern)</span>
<span class="g g-Whitespace">     </span><span class="mi">26</span> <span class="k">def</span> <span class="nf">upenn_tagset</span><span class="p">(</span><span class="n">tagpattern</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="ne">---&gt; </span><span class="mi">27</span>     <span class="n">_format_tagset</span><span class="p">(</span><span class="s2">&quot;upenn_tagset&quot;</span><span class="p">,</span> <span class="n">tagpattern</span><span class="p">)</span>

<span class="nn">File ~\anaconda3\lib\site-packages\nltk\help.py:46,</span> in <span class="ni">_format_tagset</span><span class="nt">(tagset, tagpattern)</span>
<span class="g g-Whitespace">     </span><span class="mi">45</span> <span class="k">def</span> <span class="nf">_format_tagset</span><span class="p">(</span><span class="n">tagset</span><span class="p">,</span> <span class="n">tagpattern</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="ne">---&gt; </span><span class="mi">46</span>     <span class="n">tagdict</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">&quot;help/tagsets/&quot;</span> <span class="o">+</span> <span class="n">tagset</span> <span class="o">+</span> <span class="s2">&quot;.pickle&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">47</span>     <span class="k">if</span> <span class="ow">not</span> <span class="n">tagpattern</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">48</span>         <span class="n">_print_entries</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">tagdict</span><span class="p">),</span> <span class="n">tagdict</span><span class="p">)</span>

<span class="nn">File ~\anaconda3\lib\site-packages\nltk\data.py:750,</span> in <span class="ni">load</span><span class="nt">(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)</span>
<span class="g g-Whitespace">    </span><span class="mi">747</span>     <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&lt;&lt;Loading </span><span class="si">{</span><span class="n">resource_url</span><span class="si">}</span><span class="s2">&gt;&gt;&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">749</span> <span class="c1"># Load the resource.</span>
<span class="ne">--&gt; </span><span class="mi">750</span> <span class="n">opened_resource</span> <span class="o">=</span> <span class="n">_open</span><span class="p">(</span><span class="n">resource_url</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">752</span> <span class="k">if</span> <span class="nb">format</span> <span class="o">==</span> <span class="s2">&quot;raw&quot;</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">753</span>     <span class="n">resource_val</span> <span class="o">=</span> <span class="n">opened_resource</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="nn">File ~\anaconda3\lib\site-packages\nltk\data.py:876,</span> in <span class="ni">_open</span><span class="nt">(resource_url)</span>
<span class="g g-Whitespace">    </span><span class="mi">873</span> <span class="n">protocol</span><span class="p">,</span> <span class="n">path_</span> <span class="o">=</span> <span class="n">split_resource_url</span><span class="p">(</span><span class="n">resource_url</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">875</span> <span class="k">if</span> <span class="n">protocol</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">protocol</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;nltk&quot;</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">876</span>     <span class="k">return</span> <span class="n">find</span><span class="p">(</span><span class="n">path_</span><span class="p">,</span> <span class="n">path</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">open</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">877</span> <span class="k">elif</span> <span class="n">protocol</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;file&quot;</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">878</span>     <span class="c1"># urllib might not use mode=&#39;rb&#39;, so handle this one ourselves:</span>
<span class="g g-Whitespace">    </span><span class="mi">879</span>     <span class="k">return</span> <span class="n">find</span><span class="p">(</span><span class="n">path_</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">open</span><span class="p">()</span>

<span class="nn">File ~\anaconda3\lib\site-packages\nltk\data.py:583,</span> in <span class="ni">find</span><span class="nt">(resource_name, paths)</span>
<span class="g g-Whitespace">    </span><span class="mi">581</span> <span class="n">sep</span> <span class="o">=</span> <span class="s2">&quot;*&quot;</span> <span class="o">*</span> <span class="mi">70</span>
<span class="g g-Whitespace">    </span><span class="mi">582</span> <span class="n">resource_not_found</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">sep</span><span class="si">}</span><span class="se">\n</span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="se">\n</span><span class="si">{</span><span class="n">sep</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="ne">--&gt; </span><span class="mi">583</span> <span class="k">raise</span> <span class="ne">LookupError</span><span class="p">(</span><span class="n">resource_not_found</span><span class="p">)</span>

<span class="ne">LookupError</span>: 
<span class="o">**********************************************************************</span>
  <span class="n">Resource</span> <span class="n">tagsets</span> <span class="ow">not</span> <span class="n">found</span><span class="o">.</span>
  <span class="n">Please</span> <span class="n">use</span> <span class="n">the</span> <span class="n">NLTK</span> <span class="n">Downloader</span> <span class="n">to</span> <span class="n">obtain</span> <span class="n">the</span> <span class="n">resource</span><span class="p">:</span>

  <span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">nltk</span>
  <span class="o">&gt;&gt;&gt;</span> <span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;tagsets&#39;</span><span class="p">)</span>
  
  <span class="n">For</span> <span class="n">more</span> <span class="n">information</span> <span class="n">see</span><span class="p">:</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">nltk</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="n">data</span><span class="o">.</span><span class="n">html</span>

  <span class="n">Attempted</span> <span class="n">to</span> <span class="n">load</span> <span class="n">help</span><span class="o">/</span><span class="n">tagsets</span><span class="o">/</span><span class="n">upenn_tagset</span><span class="o">.</span><span class="n">pickle</span>

  <span class="n">Searched</span> <span class="ow">in</span><span class="p">:</span>
    <span class="o">-</span> <span class="s1">&#39;C:</span><span class="se">\\</span><span class="s1">Users</span><span class="se">\\</span><span class="s1">User/nltk_data&#39;</span>
    <span class="o">-</span> <span class="s1">&#39;C:</span><span class="se">\\</span><span class="s1">Users</span><span class="se">\\</span><span class="s1">User</span><span class="se">\\</span><span class="s1">anaconda3</span><span class="se">\\</span><span class="s1">nltk_data&#39;</span>
    <span class="o">-</span> <span class="s1">&#39;C:</span><span class="se">\\</span><span class="s1">Users</span><span class="se">\\</span><span class="s1">User</span><span class="se">\\</span><span class="s1">anaconda3</span><span class="se">\\</span><span class="s1">share</span><span class="se">\\</span><span class="s1">nltk_data&#39;</span>
    <span class="o">-</span> <span class="s1">&#39;C:</span><span class="se">\\</span><span class="s1">Users</span><span class="se">\\</span><span class="s1">User</span><span class="se">\\</span><span class="s1">anaconda3</span><span class="se">\\</span><span class="s1">lib</span><span class="se">\\</span><span class="s1">nltk_data&#39;</span>
    <span class="o">-</span> <span class="s1">&#39;C:</span><span class="se">\\</span><span class="s1">Users</span><span class="se">\\</span><span class="s1">User</span><span class="se">\\</span><span class="s1">AppData</span><span class="se">\\</span><span class="s1">Roaming</span><span class="se">\\</span><span class="s1">nltk_data&#39;</span>
    <span class="o">-</span> <span class="s1">&#39;C:</span><span class="se">\\</span><span class="s1">nltk_data&#39;</span>
    <span class="o">-</span> <span class="s1">&#39;D:</span><span class="se">\\</span><span class="s1">nltk_data&#39;</span>
    <span class="o">-</span> <span class="s1">&#39;E:</span><span class="se">\\</span><span class="s1">nltk_data&#39;</span>
    <span class="o">-</span> <span class="s1">&#39;&#39;</span>
<span class="o">**********************************************************************</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="named-entity-recognition-ner">
<h2>Named Entity Recognition (NER)<a class="headerlink" href="#named-entity-recognition-ner" title="Permalink to this headline">#</a></h2>
<div class="alert alert-success">
Named entity recognition seeks to label words with the kinds of entities that they relate to.
</div>
<div class="alert alert-info">
Named entity recognition on 
<a href="https://en.wikipedia.org/wiki/Named-entity_recognition" class="alert-link">wikipedia</a>.
</div><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Apply named entity recognition to our POS tags</span>
<span class="n">entities</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">chunk</span><span class="o">.</span><span class="n">ne_chunk</span><span class="p">(</span><span class="n">tags</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check out the named entities</span>
<span class="nb">print</span><span class="p">(</span><span class="n">entities</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(S
  UC/NNP
  (PERSON San/NNP Diego/NNP)
  is/VBZ
  a/DT
  great/JJ
  place/NN
  to/TO
  study/VB
  cognitive/JJ
  science/NN
  ./.)
</pre></div>
</div>
</div>
</div>
</section>
<section id="stop-words">
<h2>Stop words<a class="headerlink" href="#stop-words" title="Permalink to this headline">#</a></h2>
<div class="alert alert-success">
'Stop words' are the most common words of a language, that we often want to filter out before text analysis. 
</div>
<div class="alert alert-info">
Stop words on 
<a href="https://en.wikipedia.org/wiki/Stop_words" class="alert-link">wikipedia</a>.
</div><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check out the corpus of stop words in English</span>
<span class="nb">print</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;i&#39;, &#39;me&#39;, &#39;my&#39;, &#39;myself&#39;, &#39;we&#39;, &#39;our&#39;, &#39;ours&#39;, &#39;ourselves&#39;, &#39;you&#39;, &quot;you&#39;re&quot;, &quot;you&#39;ve&quot;, &quot;you&#39;ll&quot;, &quot;you&#39;d&quot;, &#39;your&#39;, &#39;yours&#39;, &#39;yourself&#39;, &#39;yourselves&#39;, &#39;he&#39;, &#39;him&#39;, &#39;his&#39;, &#39;himself&#39;, &#39;she&#39;, &quot;she&#39;s&quot;, &#39;her&#39;, &#39;hers&#39;, &#39;herself&#39;, &#39;it&#39;, &quot;it&#39;s&quot;, &#39;its&#39;, &#39;itself&#39;, &#39;they&#39;, &#39;them&#39;, &#39;their&#39;, &#39;theirs&#39;, &#39;themselves&#39;, &#39;what&#39;, &#39;which&#39;, &#39;who&#39;, &#39;whom&#39;, &#39;this&#39;, &#39;that&#39;, &quot;that&#39;ll&quot;, &#39;these&#39;, &#39;those&#39;, &#39;am&#39;, &#39;is&#39;, &#39;are&#39;, &#39;was&#39;, &#39;were&#39;, &#39;be&#39;, &#39;been&#39;, &#39;being&#39;, &#39;have&#39;, &#39;has&#39;, &#39;had&#39;, &#39;having&#39;, &#39;do&#39;, &#39;does&#39;, &#39;did&#39;, &#39;doing&#39;, &#39;a&#39;, &#39;an&#39;, &#39;the&#39;, &#39;and&#39;, &#39;but&#39;, &#39;if&#39;, &#39;or&#39;, &#39;because&#39;, &#39;as&#39;, &#39;until&#39;, &#39;while&#39;, &#39;of&#39;, &#39;at&#39;, &#39;by&#39;, &#39;for&#39;, &#39;with&#39;, &#39;about&#39;, &#39;against&#39;, &#39;between&#39;, &#39;into&#39;, &#39;through&#39;, &#39;during&#39;, &#39;before&#39;, &#39;after&#39;, &#39;above&#39;, &#39;below&#39;, &#39;to&#39;, &#39;from&#39;, &#39;up&#39;, &#39;down&#39;, &#39;in&#39;, &#39;out&#39;, &#39;on&#39;, &#39;off&#39;, &#39;over&#39;, &#39;under&#39;, &#39;again&#39;, &#39;further&#39;, &#39;then&#39;, &#39;once&#39;, &#39;here&#39;, &#39;there&#39;, &#39;when&#39;, &#39;where&#39;, &#39;why&#39;, &#39;how&#39;, &#39;all&#39;, &#39;any&#39;, &#39;both&#39;, &#39;each&#39;, &#39;few&#39;, &#39;more&#39;, &#39;most&#39;, &#39;other&#39;, &#39;some&#39;, &#39;such&#39;, &#39;no&#39;, &#39;nor&#39;, &#39;not&#39;, &#39;only&#39;, &#39;own&#39;, &#39;same&#39;, &#39;so&#39;, &#39;than&#39;, &#39;too&#39;, &#39;very&#39;, &#39;s&#39;, &#39;t&#39;, &#39;can&#39;, &#39;will&#39;, &#39;just&#39;, &#39;don&#39;, &quot;don&#39;t&quot;, &#39;should&#39;, &quot;should&#39;ve&quot;, &#39;now&#39;, &#39;d&#39;, &#39;ll&#39;, &#39;m&#39;, &#39;o&#39;, &#39;re&#39;, &#39;ve&#39;, &#39;y&#39;, &#39;ain&#39;, &#39;aren&#39;, &quot;aren&#39;t&quot;, &#39;couldn&#39;, &quot;couldn&#39;t&quot;, &#39;didn&#39;, &quot;didn&#39;t&quot;, &#39;doesn&#39;, &quot;doesn&#39;t&quot;, &#39;hadn&#39;, &quot;hadn&#39;t&quot;, &#39;hasn&#39;, &quot;hasn&#39;t&quot;, &#39;haven&#39;, &quot;haven&#39;t&quot;, &#39;isn&#39;, &quot;isn&#39;t&quot;, &#39;ma&#39;, &#39;mightn&#39;, &quot;mightn&#39;t&quot;, &#39;mustn&#39;, &quot;mustn&#39;t&quot;, &#39;needn&#39;, &quot;needn&#39;t&quot;, &#39;shan&#39;, &quot;shan&#39;t&quot;, &#39;shouldn&#39;, &quot;shouldn&#39;t&quot;, &#39;wasn&#39;, &quot;wasn&#39;t&quot;, &#39;weren&#39;, &quot;weren&#39;t&quot;, &#39;won&#39;, &quot;won&#39;t&quot;, &#39;wouldn&#39;, &quot;wouldn&#39;t&quot;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="text-encoding">
<h2>Text Encoding<a class="headerlink" href="#text-encoding" title="Permalink to this headline">#</a></h2>
<p>In order to analyze text <em>as</em> data, we often need to encode it in some way.</p>
<p>By encoding here, we just mean choosing a representation of the data, and for text data the goal is to choose a representation that is more amenable for computational analysis. There are many possibilities, and which approach works best depends largely on the context of the data and the analyses to be performed. Choosing how to encode text data is a key topic in NLP.</p>
<p>Here, we will explore a couple simple encoding approaches, which in this case are basically ways to count the words and measure occurrences in text data. By measuring how often certain words occur, we can characterize the text as numerical data, and open up access to numerical analysis of the data.</p>
<p>Some common encodings for text data are:</p>
<ul class="simple">
<li><p>Bag of Words (BoW)</p>
<ul>
<li><p>Text is encoded as a collection of words &amp; frequencies</p></li>
</ul>
</li>
<li><p>Term Frequency / Inverse Document Frequency (TF/IDF)</p>
<ul>
<li><p>TF/IDF is a weighting that stores words with relation to their commonality across a corpus.</p></li>
</ul>
</li>
</ul>
<p>Next we will walk through an example of encoding text as BoW and TF-IDF.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="c1"># Standard Python has some useful string tools</span>
<span class="kn">import</span> <span class="nn">string</span>

<span class="c1"># Collections is a part of standard Python, with some useful data objects</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Scikit-learn has some useful NLP tools, such as a TFIDF vectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
</pre></div>
</div>
</div>
</div>
<section id="load-some-data">
<h3>Load some Data<a class="headerlink" href="#load-some-data" title="Permalink to this headline">#</a></h3>
<p>The data we will be looking at is a small subset of the BookCorpus dataset. The original dataset can be found here: <a class="reference external" href="http://yknzhu.wixsite.com/mbweb">http://yknzhu.wixsite.com/mbweb</a>.</p>
<p>The original dataset was collected from more than 11,000 books, and has already been tokenised at both the sentence and word level.</p>
<p>The small subset provided and used here contains the first 10,000 sentences.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the data</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;files/book10k.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
    <span class="n">sents</span> <span class="o">=</span> <span class="n">file</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check out the data - print out the first and last sentences, as examples</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sents</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sents</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>the half-ling book one in the fall of igneeria series kaylee soderburg copyright 2013 kaylee soderburg all rights reserved .

alejo was sure the fact that he was nervously repeating mass along with five wrinkly , age-encrusted spanish women meant that stalin was rethinking whether he was going to pay the price .
</pre></div>
</div>
</div>
</div>
</section>
<section id="pre-processing">
<h3>Pre-Processing<a class="headerlink" href="#pre-processing" title="Permalink to this headline">#</a></h3>
<p>First, letâ€™s do some standard text pre-processing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Preprocessing: strip all extra whitespace from the sentences</span>
<span class="n">sents</span> <span class="o">=</span> <span class="p">[</span><span class="n">sent</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">sents</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Letâ€™s first take a look at the word frequencies in this data.</p>
<p>To do so, we can tokenize the text, count occurences, and then we can have a look at the most frequent words in the dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Tokenize all the sentences into words</span>
<span class="c1">#  This collects all the word tokens together into one big list</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">sents</span><span class="p">:</span>
    <span class="n">tokens</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check out how many words are in the data</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of words in the data: </span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of unique words: </span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">tokens</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of words in the data: 	 140094
Number of unique words: 	 8221
</pre></div>
</div>
</div>
</div>
</section>
<section id="bag-of-words">
<h3>Bag-of-Words<a class="headerlink" href="#bag-of-words" title="Permalink to this headline">#</a></h3>
<p>Next, letâ€™s try a â€˜bag-of-wordsâ€™ representation of the data.</p>
<p>After tokenization, a â€˜bag-of-wordsâ€™ can be computed by counting how often each token occurs, which we can do with the <code class="docutils literal notranslate"><span class="pre">Counter</span></code> object.</p>
<div class="alert alert-success">
A 'bag of words' model, of representation, is way to represent text data by counting occurences of tokens.
</div>
<div class="alert alert-info">
Bag of words on 
<a href=https://en.wikipedia.org/wiki/Bag-of-words_model class="alert-link">wikipedia</a>.
</div><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Use the &#39;counter&#39; object to count how many times each word appears</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now, we can explore the counter object, which is basically a â€˜bag-of-wordsâ€™ representation of the data.</p>
<p>Note that in this encoding we have lost word order and grammar. All we have is a collection of words.</p>
<p>This representation is quite different from how humans interact with language, but can be useful for some analyses.</p>
<p>What we do have is a list of all the words present, and how often they appear. Basically, we have turned the text into a <em>distribution</em> and we can try and analyze this distribution to try and programmatically analyze the text.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check out the counts object, printing out some of the most common tokens</span>
<span class="n">counts</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;.&#39;, 8601),
 (&#39;,&#39;, 6675),
 (&#39;the&#39;, 6062),
 (&#39;and&#39;, 3382),
 (&#39;to&#39;, 3328),
 (&#39;``&#39;, 2852),
 (&#39;i&#39;, 2747),
 (&#39;a&#39;, 2480),
 (&#39;of&#39;, 2122),
 (&#39;was&#39;, 1752),
 (&#39;he&#39;, 1678),
 (&#39;in&#39;, 1616),
 (&#39;you&#39;, 1483),
 (&#39;her&#39;, 1353),
 (&#39;his&#39;, 1349),
 (&#39;?&#39;, 1153),
 (&#39;she&#39;, 1153),
 (&#39;that&#39;, 1134),
 (&#39;it&#39;, 1050),
 (&quot;&#39;s&quot;, 1023),
 (&#39;had&#39;, 898),
 (&#39;with&#39;, 894),
 (&#39;alejo&#39;, 890),
 (&#39;wara&#39;, 875),
 (&#39;at&#39;, 818)]
</pre></div>
</div>
</div>
</div>
<p>One thing you might notice if you scroll through the word list above is that it still contains punctuation. Letâ€™s remove those.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The &#39;string&#39; module (standard library) has a useful list of punctuation</span>
<span class="nb">print</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>!&quot;#$%&amp;&#39;()*+,-./:;&lt;=&gt;?@[\]^_`{|}~
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Drop all punction markers from the counts object</span>
<span class="k">for</span> <span class="n">punc</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">punc</span> <span class="ow">in</span> <span class="n">counts</span><span class="p">:</span>
        <span class="n">counts</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">punc</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the top 10 most frequent words</span>
<span class="n">top10</span> <span class="o">=</span> <span class="n">counts</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Extract the top words, and counts</span>
<span class="n">top10_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">it</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="n">top10</span><span class="p">]</span>
<span class="n">top10_counts</span> <span class="o">=</span> <span class="p">[</span><span class="n">it</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="n">top10</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot a barplot of the most frequent words in the text</span>
<span class="n">plt</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">top10_words</span><span class="p">,</span> <span class="n">top10_counts</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Term Frequency&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/18-NaturalLanguageProcessing_44_0.png" src="../_images/18-NaturalLanguageProcessing_44_0.png" />
</div>
</div>
<p>As we can see, â€˜theâ€™, â€˜wasâ€™, â€˜aâ€™, etc. appear a lot in the document.</p>
<p>However, these frequently appearing words arenâ€™t particularly useful for figuring out what these documents are about.</p>
<p>They do not really help us to understand this text data.</p>
<p>These words are all â€˜stop wordsâ€™, so letâ€™s drop them from the dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Drop all stop words</span>
<span class="k">for</span> <span class="n">stop</span> <span class="ow">in</span> <span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">stop</span> <span class="ow">in</span> <span class="n">counts</span><span class="p">:</span>
        <span class="n">counts</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">stop</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the top 20 most frequent words, of the stopword-removed data</span>
<span class="n">top20</span> <span class="o">=</span> <span class="n">counts</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot a barplot of the most frequent words in the text</span>
<span class="n">plt</span><span class="o">.</span><span class="n">barh</span><span class="p">([</span><span class="n">it</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="n">top20</span><span class="p">],</span> <span class="p">[</span><span class="n">it</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="n">top20</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Term Frequency&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/18-NaturalLanguageProcessing_48_0.png" src="../_images/18-NaturalLanguageProcessing_48_0.png" />
</div>
</div>
<p>This looks potentially more relevant / useful!</p>
<p>As a distribution of meaningful word, bag-of-word representations can be used to analyze text data in various ways.</p>
<p>If you are interested in further analysis of this data, look through the <code class="docutils literal notranslate"><span class="pre">nltk</span></code> tutorials for further analyses.</p>
</section>
<section id="term-frequency-inverse-document-frequency-tf-idf">
<h3>Term Frequency - Inverse Document Frequency (TF-IDF)<a class="headerlink" href="#term-frequency-inverse-document-frequency-tf-idf" title="Permalink to this headline">#</a></h3>
<p>Finally, letâ€™s look at another approach for encoding text data - term frequency / inverse document frequency.</p>
<p>Note that TF-IDF is a similar kind of word counting to bag-of-words.</p>
<p>First, letâ€™s consider a difficulty with bag-of-words encodings, which is itâ€™s difficult to interpret the word counts. For example, knowing a word occurs 10 times isnâ€™t itself really enough information to understand something about the document the word come from. If that document is 100 words long, that word seems like it must be quite important. But if the document is 10,000 words long, then this word seems less important.</p>
<p>TF-IDF tries to address this, and does so by scaling the counts of words by the typical occurrence.</p>
<ul class="simple">
<li><p>The term-frequency is the count of the term in the document, which is the same as in the bag-of-words.</p></li>
<li><p>The inverse-document-frequency is a measurement of how commonly the term occurs across a corpus.</p>
<ul>
<li><p>Since itâ€™s calculated as an inverse, a higher IDF score is a rarer word.</p></li>
</ul>
</li>
</ul>
<p>The TF-IDF score is calculated by multiplying the TF by the IDF. One way to think of this is that it normalizes, or scales, term occurrences in a document by a population measure of the occurrence of the term.</p>
<p>This allows for a representation of the text data which indicates if terms in the document of interest occur more or less frequently than expected (given a corpus). A high TF-IDF score could occur, for example, due to a relatively large number of occurrences of a typically rare term. This may be an interesting and useful feature to describe the text.</p>
<p>Here, we will briefly examine applying TF/IDF to text data. Note that in this case, we are using an object from <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> that can be used to compute the TF/IDF.</p>
<div class="alert alert-success">
Term Frequency - Inverse Document Frequency is representation of text data that scales term occurrences by corpus statistics.
</div>
<div class="alert alert-info">
TF-IDF on 
<a https://en.wikipedia.org/wiki/Tf%E2%80%93idf class="alert-link">wikipedia</a>.
</div><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize a TFIDF object, applying some settings</span>
<span class="n">tfidf</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">analyzer</span><span class="o">=</span><span class="s1">&#39;word&#39;</span><span class="p">,</span>
                        <span class="n">sublinear_tf</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">max_features</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>
                        <span class="n">tokenizer</span><span class="o">=</span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The TfidfVectorizer will calculate the inverse document frequency (IDF) for each word across our corpus of words.</p>
<p>The TFIDF for each term, for a particular document, can then be calculated as TF * IDF.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Learn the TFIDF representation of our data</span>
<span class="c1">#   Note that this takes the raw sentences, tokenizes them, and learns the TF/IDF representation</span>
<span class="n">tdidf</span> <span class="o">=</span> <span class="n">tfidf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">sents</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Before we apply this representation to our data, letâ€™s explore what the data object and calculated scores.</p>
<p>If you explore the tfidf object youâ€™ll see it includes attributes:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">vocabulary_</span></code>, which maps the terms to their indices</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">idf_</span></code>, which has the IDF values for each term.</p></li>
</ul>
<p>Letâ€™s now plot out the IDF for each of the top 10 most frequently appeared words (from the first analysis).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the IDF weights for the top 10 most common words</span>
<span class="n">IDF_weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">tfidf</span><span class="o">.</span><span class="n">idf_</span><span class="p">[</span><span class="n">tfidf</span><span class="o">.</span><span class="n">vocabulary_</span><span class="p">[</span><span class="n">token</span><span class="p">]]</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">top10_words</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the IDF scores for the very common words</span>
<span class="n">plt</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">top10_words</span><span class="p">,</span> <span class="n">IDF_weights</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Inverse Document Frequency&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;IDF Score&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/18-NaturalLanguageProcessing_56_0.png" src="../_images/18-NaturalLanguageProcessing_56_0.png" />
</div>
</div>
<p>We compare the plot with the following plot that shows the words with top 10 highest IDF.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the terms with the highest IDF score</span>
<span class="n">inds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">tfidf</span><span class="o">.</span><span class="n">idf_</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="mi">10</span><span class="p">]</span>
<span class="n">top_IDF_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">tfidf</span><span class="o">.</span><span class="n">vocabulary_</span><span class="p">)[</span><span class="n">ind</span><span class="p">]</span> <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="n">inds</span><span class="p">]</span>
<span class="n">top_IDF_scores</span> <span class="o">=</span> <span class="n">tfidf</span><span class="o">.</span><span class="n">idf_</span><span class="p">[</span><span class="n">inds</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the terms with the highest IDF score</span>
<span class="n">plt</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">top_IDF_tokens</span><span class="p">,</span> <span class="n">top_IDF_scores</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Inverse Document Frequency&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;IDF Score&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/18-NaturalLanguageProcessing_59_0.png" src="../_images/18-NaturalLanguageProcessing_59_0.png" />
</div>
</div>
<p>As we can see, comparing across the two plots, the frequently appearing words have much lower values for their IDF scores, as compared to much rarer words. This is basically by definition, for the IDF score.</p>
<p>What this means for TF-IDF is that the weighting helps account for which words in a document are specific to that document. Because the TF and IDF values are multiplied, rare terms get a higher TF-IDF score, per occurrence, than common words, which helps to compare across terms and documents. Ultimately, this allows us to represent a document by distribution of terms that are most unique to the particular document, as compared to the average across the corpus.</p>
<section id="applying-tf-idf">
<h4>Applying TF-IDF<a class="headerlink" href="#applying-tf-idf" title="Permalink to this headline">#</a></h4>
<p>Now that we have learned the frequencies, we can apply this representation to our data.</p>
<p>In the next line, we will apply the TF-IDF representation to our data, and convert this to an array.</p>
<p>This array is an <code class="docutils literal notranslate"><span class="pre">n_documents</span></code> x <code class="docutils literal notranslate"><span class="pre">n_terms</span></code> matrix that encodes the documents in a TFIDF representation.</p>
<p>Note that in our TFIDF object above we set the number of features to use as 5000, which is the number of terms.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Apply TF/IDF representation to our data</span>
<span class="n">tfidf_books</span> <span class="o">=</span> <span class="n">tdidf</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">sents</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of documents: </span><span class="se">\t\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sents</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of terms: </span><span class="se">\t\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tfidf</span><span class="o">.</span><span class="n">vocabulary_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TFIDF representation shape: </span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">tfidf_books</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of documents: 		 10000
Number of terms: 		 5000
TFIDF representation shape: 	 (10000, 5000)
</pre></div>
</div>
</div>
</div>
<p>In the TFIDF array, each row stores a representation of the document based on the TF-IDF score of our 5000 terms.</p>
<p>This is a new representation of our text data, a numerical one, that we could now use for analysis and comparison of text data.</p>
</section>
</section>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">#</a></h2>
<p>Text analysis and NLP is itself a huge field, and an area in which one can take whole classes or research programs.</p>
<p>Here, we have introduced some of the core idea related to NLP. For more information on these topics, look into NLP focused resources and classes.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Julius Welzel<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>